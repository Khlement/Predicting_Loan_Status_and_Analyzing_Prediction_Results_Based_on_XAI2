{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# Pandas and numpy for data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# No warnings about setting value on copy of slice\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "# Display up to 60 columns of a dataframe\n",
    "pd.set_option('display.max_columns', 60)\n",
    "\n",
    "# Matplotlib visualization\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Set default font size\n",
    "plt.rcParams['font.size'] = 24\n",
    "\n",
    "# Internal ipython tool for setting figure size\n",
    "from IPython.core.pylabtools import figsize\n",
    "\n",
    "# Seaborn for visualization\n",
    "import seaborn as sns\n",
    "sns.set(font_scale = 2)\n",
    "\n",
    "# Splitting, Preprocessing, and Cross-validating data into training and testing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# XGBoost for machine learning\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# For Explainable AI\n",
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "# Read in credit into a dataframe \n",
    "credit = pd.read_csv('credit_data.csv')\n",
    "credit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e2a8dd84e67164754d6d43902592a8249ec6dac8"
   },
   "outputs": [],
   "source": [
    "# Verify the column data types and non-missing values\n",
    "credit.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e516824b86742c41bce64e70d6134231e31a4ea3"
   },
   "outputs": [],
   "source": [
    "# Delete useless features\n",
    "credit.drop(labels=['Loan ID', 'Customer ID'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c0d448aee129b1a9d2dfbfe60e7ffa71c3011689"
   },
   "outputs": [],
   "source": [
    "# Preprocessing for Missing Values\n",
    "# Function to calculate missing values by column for verifying data preprocessing results\n",
    "\n",
    "def missing_values_table(df):\n",
    "        # Total missing values\n",
    "        mis_val = df.isnull().sum()\n",
    "        \n",
    "        # Percentage of missing values\n",
    "        mis_val_percent = 100 * df.isnull().sum() / len(df)\n",
    "        \n",
    "        # Make a table with the results\n",
    "        mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)\n",
    "        \n",
    "        # Rename the columns\n",
    "        mis_val_table_ren_columns = mis_val_table.rename(\n",
    "        columns = {0 : 'Missing Values', 1 : '% of Total Values'})\n",
    "        \n",
    "        # Sort the table by percentage of missing descending\n",
    "        mis_val_table_ren_columns = mis_val_table_ren_columns[\n",
    "            mis_val_table_ren_columns.iloc[:,1] != 0].sort_values(\n",
    "        '% of Total Values', ascending=False).round(1)\n",
    "        \n",
    "        # Print some summary information\n",
    "        print (\"Your selected dataframe has \" + str(df.shape[1]) + \" columns.\\n\"      \n",
    "            \"There are \" + str(mis_val_table_ren_columns.shape[0]) +\n",
    "              \" columns that have missing values.\")\n",
    "        \n",
    "        # Return the dataframe with missing information\n",
    "        return mis_val_table_ren_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "52ccf316384829ebc2b01d27ccf4b40aef37403c"
   },
   "outputs": [],
   "source": [
    "# Drop the columns with > 50% missing\n",
    "\n",
    "credit.drop(columns = 'Months since last delinquent', axis=1, inplace=True)\n",
    "credit[credit['Years of Credit History'].isnull() == True]\n",
    "\n",
    "# Here I can see that the last 514 observations are NaN values.\n",
    "\n",
    "credit.drop(credit.tail(514).index, inplace=True) # drop last 514 rows\n",
    "\n",
    "# As the number of missing values is so low in the 'Maximum Open Credit' I will drop them.\n",
    "\n",
    "for i in credit['Maximum Open Credit'][credit['Maximum Open Credit'].isnull() == True].index:\n",
    "    credit.drop(labels=i, inplace=True)\n",
    "\n",
    "# As the number of missing values is so low in the 'Tax Liens' I will drop them.\n",
    "\n",
    "for i in credit['Tax Liens'][credit['Tax Liens'].isnull() == True].index:\n",
    "    credit.drop(labels=i, inplace=True)\n",
    "\n",
    "for i in credit['Bankruptcies'][credit['Bankruptcies'].isnull() == True].index:\n",
    "    credit.drop(labels=i, inplace=True)\n",
    "\n",
    "credit.fillna(credit.mean(), inplace=True)\n",
    "\n",
    "plt.figure(figsize=(20,8))\n",
    "sns.countplot(credit['Years in current job'], order = credit['Years in current job'].value_counts().index)\n",
    "\n",
    "credit.fillna('10+ years', inplace=True) # fill with '10+ years'.\n",
    "missing_values_table(credit)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9ef51251b405bfecdc0e6c481f6a54eecd009c94"
   },
   "outputs": [],
   "source": [
    "# # # Feature Engineering and Selection\n",
    "\n",
    "credit.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "13e110a0d27ac1da28d562ad0b6d84d8bfd4cd75"
   },
   "outputs": [],
   "source": [
    "# # Encoding categorical data & Feature Scaling\n",
    "\n",
    "# Select the categorical columns\n",
    "categorical_subset = credit[['Term', 'Years in current job', 'Home Ownership', 'Purpose']]\n",
    "\n",
    "# One hot encode\n",
    "categorical_subset = pd.get_dummies(categorical_subset)\n",
    "\n",
    "# Join the dataframe in credit_train\n",
    "# Make sure to use axis = 1 to perform a column bind\n",
    "# First I will drop the 'old' categorical datas and after I will join the 'new' one.\n",
    "\n",
    "credit.drop(labels=['Term', 'Years in current job', 'Home Ownership', 'Purpose'], axis=1, inplace=True)\n",
    "credit = pd.concat([credit, categorical_subset], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b07ba1398ad974d62ccd1c65a1981915abc6976f"
   },
   "outputs": [],
   "source": [
    "# #  Remove Collinear Features\n",
    "\n",
    "def remove_collinear_features(x, threshold):\n",
    "    \n",
    "    # Dont want to remove correlations between Energy Star Score\n",
    "    y = x['Loan Status']\n",
    "    x = x.drop(columns = ['Loan Status'])\n",
    "    \n",
    "    # Calculate the correlation matrix\n",
    "    corr_matrix = x.corr()\n",
    "    iters = range(len(corr_matrix.columns) - 1)\n",
    "    drop_cols = []\n",
    "\n",
    "    # Iterate through the correlation matrix and compare correlations\n",
    "    for i in iters:\n",
    "        for j in range(i):\n",
    "            item = corr_matrix.iloc[j:(j+1), (i+1):(i+2)]\n",
    "            col = item.columns\n",
    "            row = item.index\n",
    "            val = abs(item.values)\n",
    "            \n",
    "            # If correlation exceeds the threshold\n",
    "            if val >= threshold:\n",
    "                # Print the correlated features and the correlation value\n",
    "                # print(col.values[0], \"|\", row.values[0], \"|\", round(val[0][0], 2))\n",
    "                drop_cols.append(col.values[0])\n",
    "\n",
    "    # Drop one of each pair of correlated columns\n",
    "    drops = set(drop_cols)\n",
    "    x = x.drop(columns = drops)\n",
    "    \n",
    "    # Add the score back in to the data\n",
    "    x['Loan Status'] = y\n",
    "               \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9ed921620417e13fb5641564b5090b3d7e97d86d"
   },
   "outputs": [],
   "source": [
    "# Remove the collinear features above a specified correlation coefficient\n",
    "credit = remove_collinear_features(credit, 0.6);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4be0e65c2ede81decd769b8e8768194a3c56b4cf"
   },
   "outputs": [],
   "source": [
    "credit.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "241e10723db0c1fd8df28e7afbac69d8b2b4ab1b"
   },
   "outputs": [],
   "source": [
    "# # # Split Into Training and Testing Sets\n",
    "\n",
    "# Separate out the features and targets\n",
    "features = credit.drop(columns='Loan Status')\n",
    "targets = pd.DataFrame(credit['Loan Status'])\n",
    "\n",
    "# Split into 80% training and 20% testing set\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, targets, test_size = 0.2, random_state = 42)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "349e486f1e8525e364f6be5334291ae8f00ca0cd"
   },
   "outputs": [],
   "source": [
    "# # Feature Scaling\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "# Encoding the Dependent Variable\n",
    "labelencoder_y_train = LabelEncoder()\n",
    "y_train = labelencoder_y_train.fit_transform(y_train)\n",
    "labelencoder_y_test = LabelEncoder()\n",
    "y_test = labelencoder_y_test.fit_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "03122062d1f1f41806b73d724ecc2cf403894b06"
   },
   "outputs": [],
   "source": [
    "def cross_val(X_train, y_train, model):\n",
    "    # Applying k-Fold Cross Validation\n",
    "    accuracies = cross_val_score(estimator = model, X = X_train, y = y_train, cv = 5)\n",
    "    return accuracies.mean()\n",
    "\n",
    "# Takes in a model, trains the model, and evaluates the model on the test set\n",
    "def fit_and_evaluate(model):\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions and evalute\n",
    "    model_pred = model.predict(X_test)\n",
    "    model_cross = cross_val(X_train, y_train, model)\n",
    "    \n",
    "    # Return the performance metric\n",
    "    return model_cross"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d98eaec33f4e6cadd299ec586ab840020952b6fb"
   },
   "outputs": [],
   "source": [
    "# # XGBoost Classification\n",
    "gb = XGBClassifier()\n",
    "gb_cross = fit_and_evaluate(gb)\n",
    "\n",
    "print('XGBoost Classification Performance on the test set: Cross Validation Score = %0.4f' % gb_cross)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c59406726362d253d910af2f3103608a4a1ab847"
   },
   "outputs": [],
   "source": [
    "model = XGBClassifier(loss = 'ls', max_depth = 5,\n",
    "                                  min_samples_leaf = 6,\n",
    "                                  min_samples_split = 2,\n",
    "                                  max_features = 'auto',\n",
    "                                  n_estimators = 500,\n",
    "                                  random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0679eeb425ab9195402cbc9ec0b1604981aa65de"
   },
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e22420e5d2d8928d6364322ab1f06c5db5fd9d77"
   },
   "outputs": [],
   "source": [
    "final_pred = model.predict(X_test)\n",
    "\n",
    "# Function to calculate mean absolute error\n",
    "def mse(y_true, y_pred):\n",
    "    return np.mean((y_true - y_pred)*(y_true - y_pred))\n",
    "\n",
    "print('Model performance on the test set:   MSE = %0.4f.' % mse(y_test, final_pred))\n",
    "\n",
    "# The final model does out-perform the baseline model by about less than 1% and at the cost of significantly increased running time (it's about 7 times slower on my machine). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "01603b280ddc008608d8f00f5f9cf035fea4f07e"
   },
   "outputs": [],
   "source": [
    "# # # Feature Importances\n",
    "\n",
    "# Extract the feature importances into a dataframe\n",
    "feature_results = pd.DataFrame({'Feature': list(features.columns), \n",
    "                                'Importance': model.feature_importances_})\n",
    "\n",
    "# Show the top 10 most important\n",
    "feature_results = feature_results.sort_values('Importance', ascending = False).reset_index(drop=True)\n",
    "feature_results['Rank'] = np.arange(1, len(feature_results)+1, 1)\n",
    "feature_results_rank = feature_results.set_index('Rank')\n",
    "feature_results_rank = feature_results_rank[['Feature', 'Importance']]\n",
    "feature_results_rank.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c8d1b749cf7a33872d29ed4b474fa5ef3f4cc919"
   },
   "outputs": [],
   "source": [
    "# # Use Feature Importances for Feature Selection\n",
    "\n",
    "# Extract the names of the most important features\n",
    "most_important_features = feature_results['Feature'][:10]\n",
    "\n",
    "# Find the index that corresponds to each feature name\n",
    "indices = [list(features.columns).index(x) for x in most_important_features]\n",
    "\n",
    "# Keep only the most important features\n",
    "X_train_reduced = X_train[:, indices]\n",
    "X_test_reduced = X_test[:, indices]\n",
    "\n",
    "print('Most important training features shape: ', X_train_reduced.shape)\n",
    "print('Most important testing  features shape: ', X_test_reduced.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b0a03897e8d9cabb0b43f8dc18b7d832721802b4"
   },
   "outputs": [],
   "source": [
    "# Create the model with the same hyperparamters\n",
    "model_reduced = XGBClassifier(loss='ls', max_depth=5, max_features='auto',\n",
    "                                  min_samples_leaf=6, min_samples_split=2, \n",
    "                                  n_estimators=500, random_state=42)\n",
    "\n",
    "# Fit and test on the reduced set of features\n",
    "model_reduced.fit(X_train_reduced, y_train)\n",
    "model_reduced_pred = model_reduced.predict(X_test_reduced)\n",
    "\n",
    "print('XGBoost Reduced Results: MSE = %0.4f' % mse(y_test, model_reduced_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mend the data for calculating and plotting Sharpley values\n",
    "X_train = pd.DataFrame(X_train)\n",
    "X_train.columns = features.columns\n",
    "X_train.rename(columns = {'Years in current job_< 1 year':'Years in current job less than a year'}, inplace = True)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load JS visualization code to notebook\n",
    "shap.initjs()\n",
    "\n",
    "# Explain the model's predictions using SHAP values\n",
    "explainer = shap.TreeExplainer(model)\n",
    "shap_values = explainer.shap_values(X_train)\n",
    "\n",
    "# Visualize the first prediction's explanation (use matplotlib=True to avoid Javascript)\n",
    "shap.force_plot(explainer.expected_value, \n",
    "                shap_values[idx,:], \n",
    "                X_train.iloc[idx,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize the effects of all the features\n",
    "shap.summary_plot(shap_values, X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Summrize the importance of the features\n",
    "shap.summary_plot(shap_values, X_train, plot_type=\"bar\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "c261aea317cc0286b3b3261fbba9abdec21eaa57589985bb7a274bf54d6cc0a7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
